List of interesting resources about neural network compression and performance.  

## Papers

### Compression

### Pruning
- [Learning both Weights and Connections for Efficient
Neural Networks](https://arxiv.org/pdf/1506.02626.pdf)
- [AMC: AutoML for Model Compression
and Acceleration on Mobile Devices](https://arxiv.org/pdf/1802.03494.pdf)
- [NetAdapt: Platform-Aware Neural Network
Adaptation for Mobile Applications](https://arxiv.org/pdf/1804.03230.pdf)
- [Scalpel: Customizing DNN Pruning to the Underlying
Hardware Parallelism](https://cgi.luddy.indiana.edu/~lukefahr/papers/jiecaoyu_isca17.pdf)
- [Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks](https://dl.acm.org/doi/pdf/10.5555/3546258.3546499)
- [SPDY: Accurate Pruning with Speedup Guarantees](https://arxiv.org/pdf/2201.13096.pdf)
- [The State of Sparsity in Deep Neural Networks](https://arxiv.org/pdf/1902.09574.pdf)
- [PRUNING COMPACT CONVNETS FOR EFFICIENT INFERENCE](https://arxiv.org/pdf/2301.04502.pdf)
- [WHAT IS THE STATE OF NEURAL NETWORK PRUNING?](https://arxiv.org/pdf/2003.03033.pdf)
- [COMPARING REWINDING AND FINE-TUNING
IN NEURAL NETWORK PRUNING](https://arxiv.org/pdf/2003.02389.pdf)

### Quantization

- [A Survey of Quantization Methods for Efficient
Neural Network Inference](https://arxiv.org/pdf/2103.13630.pdf)
- [A White Paper on Neural Network Quantization](https://arxiv.org/pdf/2106.08295.pdf)

### Performance
- [Sparse GPU Kernels for Deep Learning](https://arxiv.org/pdf/2006.10901.pdf)

## Vid√©os / Blog
- [Sparsity in Deep Learning: Pruning + growth for efficient inference and training in neural networks](https://www.youtube.com/watch?v=H7-p3OWPpEI)
- [Large Transformer Model Inference Optimization](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/)
- [Making Deep Learning Go Brrrr From First Principles](https://horace.io/brrr_intro.html)
- [Deep Dive on PyTorch Quantization - Chris Gottbrath](https://www.youtube.com/watch?v=c3MT2qV5f9w)